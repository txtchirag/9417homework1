{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"logo.png\" width=\"200\">\n",
    "\n",
    "<center> <h1>Linear Regression with Gradient Descent Using a Made Up Example</h1> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Gradient descent algorithm\n",
    "From our [video](https://youtu.be/fkS3FkVAPWU) on linear regression, we derived the equation to update the linear model parameters as:    \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta^{+} = \\theta^{-} + \\frac{\\alpha}{m} (y_{i} - h(x_{i}) )\\bar{x}\n",
    "\\end{equation}\n",
    "\n",
    "This minimizes the following cost function\n",
    "\n",
    "\\begin{equation}\n",
    "J(x, \\theta, y) = \\frac{1}{2m}\\sum_{i=1}^{m}(h(x_i) - y_i)^2\n",
    "\\end{equation}\n",
    "\n",
    "where\n",
    "\\begin{equation}\n",
    "h(x_i) = \\theta^T \\bar{x}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Batch gradient descent\n",
    "```FOR j FROM 0 -> max_iteration: \n",
    "    FOR i FROM 0 -> m: \n",
    "        theta += (alpha / m) * (y[i] - h(x[i])) * x_bar\n",
    "    ENDLOOP\n",
    "ENDLOOP\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Stochastic gradient descent\n",
    "```shuffle(x, y)\n",
    "FOR i FROM 0 -> m:\n",
    "    theta += (alpha / m) * (y[i] - h(x[i])) * x_bar  \n",
    "ENDLOOP\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Generate data\"\"\"\n",
    "\n",
    "df=pd.read_csv(\"Advertising.csv\")\n",
    "data=np.array(df)\n",
    "\n",
    "# 1. Pre-­‐processing:\n",
    "\n",
    "minValues = np.amin(data, axis=0)[1:5]\n",
    "maxValues = np.amax(data, axis=0)[1:5]\n",
    "\n",
    "min_TV, min_Radio, min_News, min_Sales = minValues\n",
    "max_TV, max_Radio, max_News, max_Sales = maxValues\n",
    "\n",
    "# min-max normalization\n",
    "\n",
    "for i in range(200):\n",
    "    data[i][1] = normalize(data[i][1], min_TV, max_TV)\n",
    "    data[i][2] = normalize(data[i][2], min_Radio, max_Radio)\n",
    "    data[i][3] = normalize(data[i][3], min_News, max_News)\n",
    "    data[i][4] = normalize(data[i][4], min_Sales, max_Sales)\n",
    "\n",
    "# 2. Creating test and training set\n",
    "train_data = np.copy(data[:-10])\n",
    "test_data = np.copy(data[-10:])\n",
    "\n",
    "# 3. Gradient descent\n",
    "theta0 = -1\n",
    "theta1 = -0.5\n",
    "theta = np.array([[theta0, theta1]])\n",
    "\n",
    "alpha = 0.01\n",
    "max_iter = 500\n",
    "\n",
    "#train TV x Sales\n",
    "X = train_data[:,[1]]\n",
    "y = train_data[:,[4]]\n",
    "m=X.shape[0] #no.of training data items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.scatter(input_var, output_var)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_cost(input_var, output_var, params):\n",
    "    \"Compute linear regression cost\"\n",
    "    num_samples = len(input_var)\n",
    "    cost_sum = 0.0\n",
    "    for x,y in zip(input_var, output_var):\n",
    "        y_hat = np.dot(params, np.array([1.0, x]))\n",
    "        cost_sum += (y_hat - y) ** 2\n",
    "    \n",
    "    cost = cost_sum / (num_samples * 2.0)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def lin_reg_batch_gradient_descent(input_var, output_var, params, alpha, max_iter):\n",
    "    \"\"\"Compute the params for linear regression using batch gradient descent\"\"\" \n",
    "    iteration = 0\n",
    "    num_samples = len(input_var)\n",
    "    cost = np.zeros(max_iter)\n",
    "    params_store = np.zeros([2, max_iter])\n",
    "    \n",
    "    while iteration < max_iter:\n",
    "        cost[iteration] = compute_cost(input_var, output_var, params)\n",
    "        params_store[:, iteration] = params\n",
    "        \n",
    "        print('--------------------------')\n",
    "        print(f'iteration: {iteration}')\n",
    "        print(f'cost: {cost[iteration]}')\n",
    "        \n",
    "        for x,y in zip(input_var, output_var):\n",
    "            y_hat = np.dot(params, np.array([1.0, x]))\n",
    "            gradient = np.array([1.0, x]) * (y - y_hat)\n",
    "            params += alpha * gradient/num_samples\n",
    "            \n",
    "        iteration += 1\n",
    "    \n",
    "    return params, cost, params_store\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Train the model\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_var, output_var, test_size=0.20)\n",
    "\n",
    "params_0 = np.array([20.0, 80.0])\n",
    "\n",
    "alpha_batch = 1e-3\n",
    "max_iter = 500\n",
    "params_hat_batch, cost_batch, params_store_batch =\\\n",
    "    lin_reg_batch_gradient_descent(x_train, y_train, params_0, alpha_batch, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def lin_reg_stoch_gradient_descent(input_var, output_var, params, alpha):\n",
    "    \"\"\"Compute the params for linear regression using stochastic gradient descent\"\"\"\n",
    "    num_samples = len(input_var)\n",
    "    cost = np.zeros(num_samples)\n",
    "    params_store = np.zeros([2, num_samples])\n",
    "    \n",
    "    i = 0\n",
    "    for x,y in zip(input_var, output_var):\n",
    "        cost[i] = compute_cost(input_var, output_var, params)\n",
    "        params_store[:, i] = params\n",
    "        \n",
    "        print('--------------------------')\n",
    "        print(f'iteration: {i}')\n",
    "        print(f'cost: {cost[i]}')\n",
    "        \n",
    "        y_hat = np.dot(params, np.array([1.0, x]))\n",
    "        gradient = np.array([1.0, x]) * (y - y_hat)\n",
    "        params += alpha * gradient/num_samples\n",
    "        \n",
    "        i += 1\n",
    "            \n",
    "    return params, cost, params_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "alpha = 1e-3\n",
    "params_0 = np.array([20.0, 80.0])\n",
    "params_hat, cost, params_store =\\\n",
    "lin_reg_stoch_gradient_descent(x_train, y_train, params_0, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x_test, y_test)\n",
    "plt.plot(x_test, params_hat_batch[0] + params_hat_batch[1]*x_test, 'g', label='batch')\n",
    "plt.plot(x_test, params_hat[0] + params_hat[1]*x_test, '-r', label='stochastic')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(f'batch      T0, T1: {params_hat_batch[0]}, {params_hat_batch[1]}')\n",
    "print(f'stochastic T0, T1: {params_hat[0]}, {params_hat[1]}')\n",
    "rms_batch = np.sqrt(np.mean(np.square(params_hat_batch[0] + params_hat_batch[1]*x_test - y_test)))\n",
    "rms_stochastic = np.sqrt(np.mean(np.square(params_hat[0] + params_hat[1]*x_test - y_test)))\n",
    "print(f'batch rms:      {rms_batch}')\n",
    "print(f'stochastic rms: {rms_stochastic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(max_iter), cost_batch, 'r', label='batch')\n",
    "plt.plot(np.arange(len(cost)), cost, 'g', label='stochastic')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('normalized cost')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(f'min cost with BGD: {np.min(cost_batch)}')\n",
    "print(f'min cost with SGD: {np.min(cost)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
